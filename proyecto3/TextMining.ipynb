{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7395_2.txt', '5043_3.txt', '4990_1.txt', '7261_3.txt', '4726_1.txt', '5489_1.txt', '4031_4.txt', '5892_2.txt', '8965_1.txt', '8198_4.txt', '1926_3.txt', '4903_3.txt', '854_1.txt', '5343_1.txt', '7839_4.txt', '3846_2.txt', '9276_1.txt', '3738_2.txt', '9642_4.txt', '2373_3.txt', '1723_1.txt', '8495_3.txt', '2205_2.txt', '9297_1.txt', '10905_3.txt', '7321_2.txt', '11291_1.txt', '12364_1.txt', '12194_3.txt', '10602_4.txt', '12289_1.txt', '2465_2.txt', '5621_4.txt', '4731_4.txt', '11513_3.txt', '12419_1.txt', '1655_2.txt', '8063_2.txt', '5891_3.txt', '7748_2.txt', '148_2.txt', '3923_2.txt', '10429_1.txt', '737_1.txt', '4737_3.txt', '7387_1.txt', '9302_1.txt', '410_4.txt', '11384_2.txt', '5159_2.txt', '1167_4.txt', '5291_4.txt', '1071_4.txt', '116_1.txt', '809_3.txt', '2343_4.txt', '1411_4.txt', '11264_1.txt', '9445_1.txt', '12095_3.txt', '7269_3.txt', '471_4.txt', '3560_2.txt', '1531_1.txt', '9066_4.txt', '7168_4.txt', '4931_1.txt', '5767_3.txt', '7998_1.txt', '8605_4.txt', '4664_3.txt', '4613_4.txt', '6665_3.txt', '243_3.txt', '2616_2.txt', '3161_1.txt', '840_1.txt', '3303_4.txt', '8093_3.txt', '8743_4.txt', '9399_4.txt', '2466_3.txt', '7394_2.txt', '11988_4.txt', '4366_4.txt', '1095_3.txt', '5243_4.txt', '10296_1.txt', '8368_1.txt', '11104_1.txt', '11127_3.txt', '10073_4.txt', '291_3.txt', '1963_4.txt', '11379_3.txt', '11580_2.txt', '7514_1.txt', '9739_4.txt', '5129_1.txt', '3587_3.txt']\n"
     ]
    }
   ],
   "source": [
    "# Escoge 100 archivos al azar del directorio de reviews\n",
    "reviews_folder_path = \"reviews/\"  \n",
    "all_reviews_files = os.listdir(reviews_folder_path)\n",
    "random_files = random.sample(all_reviews_files, 100)\n",
    "print(random_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reviews_url.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "urls_random_files = []\n",
    "for file in random_files:\n",
    "    first_number = file.split(\"_\")[0]\n",
    "    id = lines[int(first_number)].replace(\"/usercomments\\n\", \"\")\n",
    "    urls_random_files.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tim Watcher (Short 2003) ',\n",
       " 'Zi hu die (2003) ',\n",
       " 'Walking Tall: Lone Justice (Video 2007) ',\n",
       " 'A Town Called Bastard (1971) ',\n",
       " 'Shooting Livien (2005) ',\n",
       " 'My Favorite Martian (1999) ',\n",
       " 'The Lost Missile (1958) ',\n",
       " 'Chakushin ari (2003) ',\n",
       " 'Cube Zero (2004) ',\n",
       " 'Alien Hunter (2003) ',\n",
       " 'El Grinch (2000) ',\n",
       " 'Ci qing (2007) ',\n",
       " 'El resplandor (1980) ',\n",
       " 'S Club Seeing Double (2003) ',\n",
       " 'Shooting Dogs (2005) ',\n",
       " 'Of Human Bondage (1934) ',\n",
       " 'Omen IV: The Awakening (TV Movie 1991) ',\n",
       " 'Made Men (1999) ',\n",
       " 'Biohazard (1985) ',\n",
       " \"Freddy's Dead: The Final Nightmare (1991) \",\n",
       " 'The Crater Lake Monster (1977) ',\n",
       " 'Conceiving Ada (1997) ',\n",
       " 'Hammerhead (TV Movie 2005) ',\n",
       " 'Executive Power (Video 1997) ',\n",
       " 'The Animal (2001) ',\n",
       " 'Acting on Impulse (1993) ',\n",
       " \"Sharks' Treasure (1975) \",\n",
       " 'Loonatics Unleashed (TV Series 2005–2007) ',\n",
       " 'Ricordati di me (2003) ',\n",
       " 'Universal Soldier: The Return (1999) ',\n",
       " 'La casa 4 (Witchcraft) (1988) ',\n",
       " 'Second to Die (2002) ',\n",
       " \"The God Who Wasn't There (2005) \",\n",
       " 'Live a Little, Love a Little (1968) ',\n",
       " 'Swept Away (2002) ',\n",
       " \"Adama Meshuga'at (2006) \",\n",
       " 'Ekstase (1933) ',\n",
       " 'Soul Survivors (2001) ',\n",
       " 'United (2003) ',\n",
       " 'Attack of the Sabretooth (TV Movie 2005) ',\n",
       " 'The Witches Hammer (2006) ',\n",
       " 'Liliom (1930) ',\n",
       " '\"Battlestar Galactica\" Daybreak: Part 2 (TV Episode 2009) ',\n",
       " 'The War of the Worlds (Video 2005) ',\n",
       " 'Azumi 2: Death or Love (2005) ',\n",
       " 'Attack Force (Video 2006) ',\n",
       " 'S.I.C.K. Serial Insane Clown Killer (Video 2003) ',\n",
       " 'Hollow Man (2000) ',\n",
       " 'Reveille with Beverly (1943) ',\n",
       " 'Toys (1992) ',\n",
       " 'Alive (2002) ',\n",
       " 'Nil by Mouth (1997) ',\n",
       " 'The Gingerbread Man (1998) ',\n",
       " 'They All Laughed (1981) ',\n",
       " 'K',\n",
       " 'Any Way the Wind Blows (2003) ',\n",
       " '10 Items or Less (2006) ',\n",
       " 'Rancid Aluminium (2000) ',\n",
       " 'The Cat in the Hat (2003) ',\n",
       " 'La pianiste (2001) ',\n",
       " 'El cielo dividido (2006) ',\n",
       " 'Up the Academy (1980) ',\n",
       " 'Vuxna människor (1999) ',\n",
       " 'Men in White (TV Movie 1998) ',\n",
       " 'Phone Call from a Stranger (1952) ',\n",
       " 'Trance (1998) ',\n",
       " 'Silent Night, Deadly Night 5: The Toy Maker (Video 1991) ',\n",
       " 'Elephants Dream (Video 2006) ',\n",
       " 'Denis Leary: No Cure for Cancer (TV Special 1993) ',\n",
       " 'Slugs, muerte viscosa (1988) ',\n",
       " 'The Pillow Book (1995) ',\n",
       " \"Prizzi's Honor (1985) \",\n",
       " 'Down in the Valley (2005) ',\n",
       " 'Finding John Christmas (TV Movie 2003) ',\n",
       " '102 Dalmatians (2000) ',\n",
       " 'Over Her Dead Body (2008) ',\n",
       " 'Love.com (2002) ',\n",
       " 'Rånarna (2003) ',\n",
       " 'The Bonfire of the Vanities (1990) ',\n",
       " 'Antitrust (2001) ',\n",
       " 'Suicide Fleet (1931) ',\n",
       " 'Fido (2006) ',\n",
       " 'Attack Force (Video 2006) ',\n",
       " 'A Cry in the Wild (1990) ',\n",
       " '\"Los expedientes secretos X\" Roadrunners (TV Episode 2000) ',\n",
       " 'Tigerland (2000) ',\n",
       " 'Role Models (2008) ',\n",
       " 'Morvern Callar (2002) ',\n",
       " 'Little Man (2006) ',\n",
       " 'The Midnight Meat Train (2008) ',\n",
       " 'Native Son (1986) ',\n",
       " 'Grease 2 (1982) ',\n",
       " \"Without You I'm Nothing (1990) \",\n",
       " 'The Tooth Fairy (Video 2006) ',\n",
       " 'Robotboy (TV Series 2005–2008) ',\n",
       " 'Keys to Tulsa (1997) ',\n",
       " \"Hallow's End (Video 2003) \",\n",
       " 'Spontaneous Combustion (1989) ',\n",
       " 'The Truth About Cats & Dogs (1996) ',\n",
       " 'Walking Tall Part II (1975) ']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = []\n",
    "session = HTMLSession()\n",
    "\n",
    "for url in urls_random_files:\n",
    "    respone = session.get(url)\n",
    "    page_html = respone.html\n",
    "    title= page_html.find('title')[0].text\n",
    "    final_title = title.split(\"-\")[0]\n",
    "    titles.append(final_title)\n",
    "\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized files have been created in the 'lemmatized_reviews' directory.\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamiento de los 100 archivos escogidos\n",
    "# Incluye eliminar numeros, tildes y caracteres adiciones\n",
    "# Lematizacion\n",
    "\n",
    "lemmatized_directory = 'lemmatized_reviews/'\n",
    "os.makedirs(lemmatized_directory, exist_ok=True)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "for file in random_files:\n",
    "    path = os.path.join(reviews_folder_path, file)\n",
    "        \n",
    "    with open(path, 'r') as archivo:\n",
    "        text = archivo.read()\n",
    "        text=text.lower()\n",
    "        text=text.replace(\"< br / >\",\"\")\n",
    "        text=text.replace(\"<br />\",\"\")\n",
    "        text=text.replace(\"´\", \"'\")\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "        filtered = [word for word in filtered_tokens if word.isalpha() and word not in stop_words]\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered]\n",
    "        lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "            \n",
    "        # Create a new file with lemmatized content\n",
    "        lemmatized_path = os.path.join(lemmatized_directory, file)\n",
    "        with open(lemmatized_path, \"w\") as output_file:\n",
    "            output_file.write(lemmatized_text)\n",
    "\n",
    "print(\"Lemmatized files have been created in the 'lemmatized_reviews' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for filename in random_files:\n",
    "    file_number = filename.split(\"_\")[1].split('.')[0]\n",
    "\n",
    "    with open(os.path.join(lemmatized_directory, filename), 'r') as input_file:\n",
    "        file_content = input_file.read()\n",
    "        documents.append(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frecuencia por documento vectorizado \n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "term_frequency = X.toarray()\n",
    "document_frequency = np.sum(X > 0, axis=0)\n",
    "document_frequency = document_frequency.tolist()[0]\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_vectors = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7395_2.txt</th>\n",
       "      <th>5043_3.txt</th>\n",
       "      <th>4990_1.txt</th>\n",
       "      <th>7261_3.txt</th>\n",
       "      <th>4726_1.txt</th>\n",
       "      <th>5489_1.txt</th>\n",
       "      <th>4031_4.txt</th>\n",
       "      <th>5892_2.txt</th>\n",
       "      <th>8965_1.txt</th>\n",
       "      <th>8198_4.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>11127_3.txt</th>\n",
       "      <th>10073_4.txt</th>\n",
       "      <th>291_3.txt</th>\n",
       "      <th>1963_4.txt</th>\n",
       "      <th>11379_3.txt</th>\n",
       "      <th>11580_2.txt</th>\n",
       "      <th>7514_1.txt</th>\n",
       "      <th>9739_4.txt</th>\n",
       "      <th>5129_1.txt</th>\n",
       "      <th>3587_3.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abnormal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aboard</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ziyi</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombierelated</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zootheme</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4615 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               7395_2.txt  5043_3.txt  4990_1.txt  7261_3.txt  4726_1.txt  \\\n",
       "abandoned               0           0           0           0           0   \n",
       "ability                 0           0           0           0           0   \n",
       "able                    0           0           0           0           0   \n",
       "abnormal                0           0           0           0           0   \n",
       "aboard                  0           0           0           0           0   \n",
       "...                   ...         ...         ...         ...         ...   \n",
       "ziyi                    0           2           0           0           0   \n",
       "zombie                  0           0           0           0           0   \n",
       "zombierelated           0           0           0           0           0   \n",
       "zone                    0           0           0           0           0   \n",
       "zootheme                0           0           0           0           0   \n",
       "\n",
       "               5489_1.txt  4031_4.txt  5892_2.txt  8965_1.txt  8198_4.txt  \\\n",
       "abandoned               0           0           0           0           0   \n",
       "ability                 0           0           0           0           0   \n",
       "able                    0           0           0           0           0   \n",
       "abnormal                0           0           0           0           0   \n",
       "aboard                  0           1           0           0           0   \n",
       "...                   ...         ...         ...         ...         ...   \n",
       "ziyi                    0           0           0           0           0   \n",
       "zombie                  0           0           0           0           0   \n",
       "zombierelated           0           0           0           0           0   \n",
       "zone                    0           0           0           0           0   \n",
       "zootheme                0           0           0           0           0   \n",
       "\n",
       "               ...  11127_3.txt  10073_4.txt  291_3.txt  1963_4.txt  \\\n",
       "abandoned      ...            0            0          0           0   \n",
       "ability        ...            0            0          0           0   \n",
       "able           ...            0            0          0           0   \n",
       "abnormal       ...            0            0          0           0   \n",
       "aboard         ...            0            0          0           0   \n",
       "...            ...          ...          ...        ...         ...   \n",
       "ziyi           ...            0            0          0           0   \n",
       "zombie         ...            0            0          0           0   \n",
       "zombierelated  ...            0            0          0           0   \n",
       "zone           ...            0            0          0           0   \n",
       "zootheme       ...            0            0          0           0   \n",
       "\n",
       "               11379_3.txt  11580_2.txt  7514_1.txt  9739_4.txt  5129_1.txt  \\\n",
       "abandoned                0            0           0           0           0   \n",
       "ability                  0            0           0           0           0   \n",
       "able                     0            0           0           0           0   \n",
       "abnormal                 0            0           0           0           0   \n",
       "aboard                   0            0           0           0           0   \n",
       "...                    ...          ...         ...         ...         ...   \n",
       "ziyi                     0            0           0           0           0   \n",
       "zombie                   0            0           0           0           0   \n",
       "zombierelated            0            0           0           0           0   \n",
       "zone                     0            0           0           0           0   \n",
       "zootheme                 0            0           0           0           0   \n",
       "\n",
       "               3587_3.txt  \n",
       "abandoned               0  \n",
       "ability                 0  \n",
       "able                    0  \n",
       "abnormal                0  \n",
       "aboard                  0  \n",
       "...                   ...  \n",
       "ziyi                    0  \n",
       "zombie                  0  \n",
       "zombierelated           0  \n",
       "zone                    0  \n",
       "zootheme                0  \n",
       "\n",
       "[4615 rows x 100 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "word_freq_dicts = {}\n",
    "\n",
    "for random_files_index, random_file in enumerate(random_files):\n",
    "    name_doc = \"Doc\"+ str(random_files_index) + \"_tf\"\n",
    "    word_freq_per_doc_dict = {}\n",
    "    for word_index, word in enumerate(feature_names):\n",
    "        word_freq_per_doc_dict[word] = int(term_frequency[random_files_index][word_index])\n",
    "    \n",
    "    word_freq_dicts[random_file] = word_freq_per_doc_dict\n",
    "\n",
    "freq_df = pd.DataFrame(word_freq_dicts)\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_tf</th>\n",
       "      <th>df</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>normalized_tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>6.442085</td>\n",
       "      <td>68</td>\n",
       "      <td>0.167491</td>\n",
       "      <td>1.078992</td>\n",
       "      <td>0.046375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>5.827881</td>\n",
       "      <td>58</td>\n",
       "      <td>0.236572</td>\n",
       "      <td>1.378713</td>\n",
       "      <td>0.059258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>3.100557</td>\n",
       "      <td>52</td>\n",
       "      <td>0.283997</td>\n",
       "      <td>0.880548</td>\n",
       "      <td>0.037846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>3.064812</td>\n",
       "      <td>54</td>\n",
       "      <td>0.267606</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>0.035251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character</th>\n",
       "      <td>3.019550</td>\n",
       "      <td>39</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>1.234801</td>\n",
       "      <td>0.053072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>2.517052</td>\n",
       "      <td>35</td>\n",
       "      <td>0.455932</td>\n",
       "      <td>1.147604</td>\n",
       "      <td>0.049324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>2.459905</td>\n",
       "      <td>31</td>\n",
       "      <td>0.508638</td>\n",
       "      <td>1.251202</td>\n",
       "      <td>0.053777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>2.458946</td>\n",
       "      <td>36</td>\n",
       "      <td>0.443697</td>\n",
       "      <td>1.091028</td>\n",
       "      <td>0.046893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plot</th>\n",
       "      <td>2.419400</td>\n",
       "      <td>37</td>\n",
       "      <td>0.431798</td>\n",
       "      <td>1.044693</td>\n",
       "      <td>0.044901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>2.418317</td>\n",
       "      <td>36</td>\n",
       "      <td>0.443697</td>\n",
       "      <td>1.073001</td>\n",
       "      <td>0.046118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           total_tf  df       idf    tf_idf  normalized_tf_idf\n",
       "movie      6.442085  68  0.167491  1.078992           0.046375\n",
       "film       5.827881  58  0.236572  1.378713           0.059258\n",
       "like       3.100557  52  0.283997  0.880548           0.037846\n",
       "one        3.064812  54  0.267606  0.820163           0.035251\n",
       "character  3.019550  39  0.408935  1.234801           0.053072\n",
       "get        2.517052  35  0.455932  1.147604           0.049324\n",
       "bad        2.459905  31  0.508638  1.251202           0.053777\n",
       "really     2.458946  36  0.443697  1.091028           0.046893\n",
       "plot       2.419400  37  0.431798  1.044693           0.044901\n",
       "would      2.418317  36  0.443697  1.073001           0.046118"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_freq = freq_df.sum(axis=1)\n",
    "all_metrics_df = pd.DataFrame({\"total_tf\": total_freq})\n",
    "\n",
    "all_metrics_df[\"df\"] = document_frequency#df_dict.values()\n",
    "all_metrics_df['idf'] = np.log10(100 / all_metrics_df['df'])\n",
    "all_metrics_df['tf_idf'] = all_metrics_df['idf'] * all_metrics_df['total_tf']\n",
    "all_metrics_df_sorted = all_metrics_df.sort_values(by='total_tf', ascending=False)\n",
    "normalized_column = normalize(all_metrics_df_sorted[['tf_idf']], norm='l2', axis=0)\n",
    "all_metrics_df_sorted['normalized_tf_idf'] = normalized_column\n",
    "\n",
    "all_metrics_df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_tf</th>\n",
       "      <th>df</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>normalized_tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actor</th>\n",
       "      <td>1.832096</td>\n",
       "      <td>15</td>\n",
       "      <td>0.823909</td>\n",
       "      <td>1.509480</td>\n",
       "      <td>0.064878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kibbutz</th>\n",
       "      <td>0.719361</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.438723</td>\n",
       "      <td>0.061837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>show</th>\n",
       "      <td>1.658870</td>\n",
       "      <td>14</td>\n",
       "      <td>0.853872</td>\n",
       "      <td>1.416462</td>\n",
       "      <td>0.060880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>5.827881</td>\n",
       "      <td>58</td>\n",
       "      <td>0.236572</td>\n",
       "      <td>1.378713</td>\n",
       "      <td>0.059258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>1.999280</td>\n",
       "      <td>21</td>\n",
       "      <td>0.677781</td>\n",
       "      <td>1.355073</td>\n",
       "      <td>0.058241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joke</th>\n",
       "      <td>1.199305</td>\n",
       "      <td>8</td>\n",
       "      <td>1.096910</td>\n",
       "      <td>1.315529</td>\n",
       "      <td>0.056542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretty</th>\n",
       "      <td>1.459821</td>\n",
       "      <td>13</td>\n",
       "      <td>0.886057</td>\n",
       "      <td>1.293484</td>\n",
       "      <td>0.055594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <td>1.204717</td>\n",
       "      <td>9</td>\n",
       "      <td>1.045757</td>\n",
       "      <td>1.259842</td>\n",
       "      <td>0.054148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>2.459905</td>\n",
       "      <td>31</td>\n",
       "      <td>0.508638</td>\n",
       "      <td>1.251202</td>\n",
       "      <td>0.053777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horror</th>\n",
       "      <td>1.081837</td>\n",
       "      <td>7</td>\n",
       "      <td>1.154902</td>\n",
       "      <td>1.249416</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         total_tf  df       idf    tf_idf  normalized_tf_idf\n",
       "actor    1.832096  15  0.823909  1.509480           0.064878\n",
       "kibbutz  0.719361   1  2.000000  1.438723           0.061837\n",
       "show     1.658870  14  0.853872  1.416462           0.060880\n",
       "film     5.827881  58  0.236572  1.378713           0.059258\n",
       "story    1.999280  21  0.677781  1.355073           0.058241\n",
       "joke     1.199305   8  1.096910  1.315529           0.056542\n",
       "pretty   1.459821  13  0.886057  1.293484           0.055594\n",
       "book     1.204717   9  1.045757  1.259842           0.054148\n",
       "bad      2.459905  31  0.508638  1.251202           0.053777\n",
       "horror   1.081837   7  1.154902  1.249416           0.053700"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics_df_new_sorted = all_metrics_df_sorted.sort_values(by='tf_idf', ascending=False)\n",
    "all_metrics_df_new_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7395_2.txt</th>\n",
       "      <th>5043_3.txt</th>\n",
       "      <th>4990_1.txt</th>\n",
       "      <th>7261_3.txt</th>\n",
       "      <th>4726_1.txt</th>\n",
       "      <th>5489_1.txt</th>\n",
       "      <th>4031_4.txt</th>\n",
       "      <th>5892_2.txt</th>\n",
       "      <th>8965_1.txt</th>\n",
       "      <th>8198_4.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>11127_3.txt</th>\n",
       "      <th>10073_4.txt</th>\n",
       "      <th>291_3.txt</th>\n",
       "      <th>1963_4.txt</th>\n",
       "      <th>11379_3.txt</th>\n",
       "      <th>11580_2.txt</th>\n",
       "      <th>7514_1.txt</th>\n",
       "      <th>9739_4.txt</th>\n",
       "      <th>5129_1.txt</th>\n",
       "      <th>3587_3.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abnormal</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aboard</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ziyi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombierelated</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zootheme</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4615 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               7395_2.txt  5043_3.txt  4990_1.txt  7261_3.txt  4726_1.txt  \\\n",
       "abandoned             0.0    0.000000         0.0         0.0         0.0   \n",
       "ability               0.0    0.000000         0.0         0.0         0.0   \n",
       "able                  0.0    0.000000         0.0         0.0         0.0   \n",
       "abnormal              0.0    0.000000         0.0         0.0         0.0   \n",
       "aboard                0.0    0.000000         0.0         0.0         0.0   \n",
       "...                   ...         ...         ...         ...         ...   \n",
       "ziyi                  0.0    0.228334         0.0         0.0         0.0   \n",
       "zombie                0.0    0.000000         0.0         0.0         0.0   \n",
       "zombierelated         0.0    0.000000         0.0         0.0         0.0   \n",
       "zone                  0.0    0.000000         0.0         0.0         0.0   \n",
       "zootheme              0.0    0.000000         0.0         0.0         0.0   \n",
       "\n",
       "               5489_1.txt  4031_4.txt  5892_2.txt  8965_1.txt  8198_4.txt  \\\n",
       "abandoned             0.0    0.000000         0.0         0.0         0.0   \n",
       "ability               0.0    0.000000         0.0         0.0         0.0   \n",
       "able                  0.0    0.000000         0.0         0.0         0.0   \n",
       "abnormal              0.0    0.000000         0.0         0.0         0.0   \n",
       "aboard                0.0    0.051401         0.0         0.0         0.0   \n",
       "...                   ...         ...         ...         ...         ...   \n",
       "ziyi                  0.0    0.000000         0.0         0.0         0.0   \n",
       "zombie                0.0    0.000000         0.0         0.0         0.0   \n",
       "zombierelated         0.0    0.000000         0.0         0.0         0.0   \n",
       "zone                  0.0    0.000000         0.0         0.0         0.0   \n",
       "zootheme              0.0    0.000000         0.0         0.0         0.0   \n",
       "\n",
       "               ...  11127_3.txt  10073_4.txt  291_3.txt  1963_4.txt  \\\n",
       "abandoned      ...          0.0          0.0        0.0         0.0   \n",
       "ability        ...          0.0          0.0        0.0         0.0   \n",
       "able           ...          0.0          0.0        0.0         0.0   \n",
       "abnormal       ...          0.0          0.0        0.0         0.0   \n",
       "aboard         ...          0.0          0.0        0.0         0.0   \n",
       "...            ...          ...          ...        ...         ...   \n",
       "ziyi           ...          0.0          0.0        0.0         0.0   \n",
       "zombie         ...          0.0          0.0        0.0         0.0   \n",
       "zombierelated  ...          0.0          0.0        0.0         0.0   \n",
       "zone           ...          0.0          0.0        0.0         0.0   \n",
       "zootheme       ...          0.0          0.0        0.0         0.0   \n",
       "\n",
       "               11379_3.txt  11580_2.txt  7514_1.txt  9739_4.txt  5129_1.txt  \\\n",
       "abandoned              0.0          0.0         0.0         0.0         0.0   \n",
       "ability                0.0          0.0         0.0         0.0         0.0   \n",
       "able                   0.0          0.0         0.0         0.0         0.0   \n",
       "abnormal               0.0          0.0         0.0         0.0         0.0   \n",
       "aboard                 0.0          0.0         0.0         0.0         0.0   \n",
       "...                    ...          ...         ...         ...         ...   \n",
       "ziyi                   0.0          0.0         0.0         0.0         0.0   \n",
       "zombie                 0.0          0.0         0.0         0.0         0.0   \n",
       "zombierelated          0.0          0.0         0.0         0.0         0.0   \n",
       "zone                   0.0          0.0         0.0         0.0         0.0   \n",
       "zootheme               0.0          0.0         0.0         0.0         0.0   \n",
       "\n",
       "               3587_3.txt  \n",
       "abandoned             0.0  \n",
       "ability               0.0  \n",
       "able                  0.0  \n",
       "abnormal              0.0  \n",
       "aboard                0.0  \n",
       "...                   ...  \n",
       "ziyi                  0.0  \n",
       "zombie                0.0  \n",
       "zombierelated         0.0  \n",
       "zone                  0.0  \n",
       "zootheme              0.0  \n",
       "\n",
       "[4615 rows x 100 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_dicts = {}\n",
    "\n",
    "for random_files_index, random_file in enumerate(random_files):\n",
    "    name_doc = \"Doc\"+ str(random_files_index) + \"tf_idf\"\n",
    "    word_freq_per_doc_dict = {}\n",
    "    for word_index, word in enumerate(feature_names):\n",
    "        word_freq_per_doc_dict[word] = tfidf_vectors[random_files_index][word_index]\n",
    "    \n",
    "    word_freq_dicts[random_file] = word_freq_per_doc_dict\n",
    "\n",
    "freq_df = pd.DataFrame(word_freq_dicts)\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00922838, 0.02552782, 0.02687279, 0.        ,\n",
       "        0.03621537, 0.        , 0.04344503, 0.        , 0.01999301,\n",
       "        0.        , 0.01997679, 0.04441722, 0.        , 0.06545443,\n",
       "        0.        , 0.02356506, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01807174, 0.        , 0.01322742,\n",
       "        0.00759715, 0.03404838, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00795893, 0.        , 0.        , 0.        ,\n",
       "        0.02459195, 0.02343485, 0.03507767, 0.0205157 , 0.05254071,\n",
       "        0.01936039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01146033, 0.        , 0.        , 0.        , 0.01371885,\n",
       "        0.        , 0.        , 0.        , 0.05334392, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.02384829, 0.        ,\n",
       "        0.        , 0.03832874, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00883187, 0.        , 0.        ,\n",
       "        0.02926271, 0.        , 0.        , 0.        , 0.01727915,\n",
       "        0.        , 0.02498123, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the query_text (replace this with your actual query)\n",
    "query_text = \"made me cry\"\n",
    "\n",
    "# Calculate the TF-IDF vector for the query\n",
    "query_vector = tfidf_vectorizer.transform([query_text]).toarray()\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate cosine similarity between the query vector and document vectors\n",
    "similarities = cosine_similarity(query_vector, tfidf_vectors)\n",
    "\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  Freddy's Dead: The Final Nightmare (1991)  ---- File name:  2373_3.txt ---- Review:  warning review contains mild spoilersa couple year back managed see first five film franchise planning overview whole elm st series however two year find cant remember enough order guess couldnt made much impression recall sequel dream warrior particular werent bad often made though even original classic generally predictability premise people fall asleep get murdered dream doesnt lend narrative tension recall much first five film know never plumbed depth freddys deadan indication sick freddy public point judged fact film promoted solely character demise fact movie conclusion even hidden fact entire purpose film go illustrate vacant soulless cynical venture wastaking morally questionable idea child molester charismatic villain robert englunds innowayscary interpretation boom laughter always thought freddys mockery teenage victim le aimed character teenage audience could ever watch tripe like englunds cry know garbage youre paying see who one laughing im sure victim child abuse would disheartened see insensitive depiction plight freddys appearance film always rudimentary get haaaaaaaaaaaaaarr har har hars thats elm st film youd ever seen wouldnt get know character even character predeath flashback englund play boohiss pantomime villain slop transatlantic ie overstated misplaced funny ironyacting almost universally poor look many time breckin meyer overacts hand gesture body language kananga yaphet kotto keep dignity roseanne tom arnold alice cooper show almost visibly see film sinking mire script absolutely lousy almost wholly without merit carlos ricky dean logan open road map upon noel cowardlike freddy wittily written youre fked prompted map carlos responds well map say fked wrote screenplay oscar wildeor scene carlos tortured freddy hearing enhanced painful level freddy torment threatening drop pin potentially fatal sound given sound magnified oddly fact carlos shout top voice drop seems effect nice hearing carlos quip freddy hoping better line come along also worth noting dream sleep doesnt occur instaneously knocked unconscious wouldnt allow instant access freddys world though part narrative contains human computer game finale plot logic isnt high list requirementsthe teenager heading cast time really obnoxious dislikeable group whole series tracy lezlie deane one get greet freddy shut fk man kick scallop incongruous pop music always part ingredient freddys dead laugh scare interest fun\n",
      "Title:  Men in White (TV Movie 1998)  ---- File name:  1531_1.txt ---- Review:  film bad made want vomit poorly produced complete laugh free zone name god would spoof movie degree spoof damn funny one stand set laughable effect bad arent even laughable acting farcical complete mystery would even consider watching lump garbage national lampoon made animal house people still consider completely utterly hilarious theyve relegated making tv movie like lump name expletive could accurately used describe film\n",
      "Title:  Toys (1992)  ---- File name:  5159_2.txt ---- Review:  watching movie like eating banquet nothing meringue initially look great ultimately provides satisfactionnonethe plot muddled mess toy factory force evil possible basic plot robin williams movie still turn badly picture appearance substance whatsoevermuch like terrible popeye picture williams beginning film career film must cost fortune perhaps wasnt enough money left hire writer graduated grade schoolthe film one unfunny joke go really unsure made first placeit certainly wasnt made provide sort entertainment\n",
      "Title:  Made Men (1999)  ---- File name:  3738_2.txt ---- Review:  thats title anywaythis movie combine gun explosive mindless killing make one flop action movie let make point series question answer type dealwhat happens movie people dieis yeswhat plot plotwhat point movie trying make killing solutionwhat character like extremely flawed contradictive toward personalitiesis anything good movie yes im sure used nice panavision camera filming itif like constant killing greed watch movie happen repulsed lowstandard entertainment made men youto sum plotline stink character arent worth storyline completely resistable nothing fit togetherthis prof one thing actor director whoever helped make movie certainly arent made\n",
      "Title:  El resplandor (1980)  ---- File name:  854_1.txt ---- Review:  lady gentlemenplease dont get fooled stanley kubrick film tagthis bad film unfortunately hailed one deadliest horror film ever madehorror film create fear night people shiver heart thinking true horror filmin shiningthere real horror find instead naivefoolish attempt made create chilling horroreveryone know good attempt different realityall good film view icy valley hotel actor lodged appears good tooa word actor jack nicholson look like lostlazy soul never really sure supposed dothere much said baldcolored actor time busy pampering kid actorno need blame bad weather tragedyit avoided film made poor kubrick alive make change\n"
     ]
    }
   ],
   "source": [
    "# Get the indices of the top-N most similar documents\n",
    "top_indices = np.argsort(similarities[0])[::-1][:5]\n",
    "\n",
    "top_titles = []\n",
    "top_file_names = []\n",
    "\n",
    "for index in top_indices:\n",
    "    print(\"Title: \",titles[index], end=\" ---- \")\n",
    "    print(\"File name: \", random_files[index], end=\" ---- \")\n",
    "    print(\"Review: \", documents[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080066</td>\n",
       "      <td>0.061542</td>\n",
       "      <td>0.058908</td>\n",
       "      <td>0.052581</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>0.051660</td>\n",
       "      <td>0.043490</td>\n",
       "      <td>0.089278</td>\n",
       "      <td>0.068814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069883</td>\n",
       "      <td>0.028730</td>\n",
       "      <td>0.062394</td>\n",
       "      <td>0.052185</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.054693</td>\n",
       "      <td>0.058060</td>\n",
       "      <td>0.039148</td>\n",
       "      <td>0.039159</td>\n",
       "      <td>0.041565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080066</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.104372</td>\n",
       "      <td>0.096369</td>\n",
       "      <td>0.035761</td>\n",
       "      <td>0.039454</td>\n",
       "      <td>0.074098</td>\n",
       "      <td>0.094881</td>\n",
       "      <td>0.028813</td>\n",
       "      <td>0.063958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044616</td>\n",
       "      <td>0.059069</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.061235</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.059608</td>\n",
       "      <td>0.021587</td>\n",
       "      <td>0.055069</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>0.021278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061542</td>\n",
       "      <td>0.104372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046375</td>\n",
       "      <td>0.053976</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>0.065979</td>\n",
       "      <td>0.085059</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.037902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013196</td>\n",
       "      <td>0.071385</td>\n",
       "      <td>0.044981</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>0.121208</td>\n",
       "      <td>0.050611</td>\n",
       "      <td>0.007815</td>\n",
       "      <td>0.020025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058908</td>\n",
       "      <td>0.096369</td>\n",
       "      <td>0.046375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035663</td>\n",
       "      <td>0.050514</td>\n",
       "      <td>0.069387</td>\n",
       "      <td>0.082785</td>\n",
       "      <td>0.071459</td>\n",
       "      <td>0.036879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024534</td>\n",
       "      <td>0.053544</td>\n",
       "      <td>0.036607</td>\n",
       "      <td>0.034040</td>\n",
       "      <td>0.027670</td>\n",
       "      <td>0.025298</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.039101</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.022963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052581</td>\n",
       "      <td>0.035761</td>\n",
       "      <td>0.053976</td>\n",
       "      <td>0.035663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038615</td>\n",
       "      <td>0.057243</td>\n",
       "      <td>0.042069</td>\n",
       "      <td>0.039807</td>\n",
       "      <td>0.038635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023546</td>\n",
       "      <td>0.022473</td>\n",
       "      <td>0.031935</td>\n",
       "      <td>0.029203</td>\n",
       "      <td>0.040399</td>\n",
       "      <td>0.069555</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.044359</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.019603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.054693</td>\n",
       "      <td>0.059608</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>0.025298</td>\n",
       "      <td>0.069555</td>\n",
       "      <td>0.025346</td>\n",
       "      <td>0.054146</td>\n",
       "      <td>0.022813</td>\n",
       "      <td>0.030327</td>\n",
       "      <td>0.029828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044763</td>\n",
       "      <td>0.024386</td>\n",
       "      <td>0.055134</td>\n",
       "      <td>0.046696</td>\n",
       "      <td>0.030511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015322</td>\n",
       "      <td>0.026704</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>0.027652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.058060</td>\n",
       "      <td>0.021587</td>\n",
       "      <td>0.121208</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.037258</td>\n",
       "      <td>0.051903</td>\n",
       "      <td>0.026425</td>\n",
       "      <td>0.043188</td>\n",
       "      <td>0.052317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016540</td>\n",
       "      <td>0.057773</td>\n",
       "      <td>0.024460</td>\n",
       "      <td>0.042650</td>\n",
       "      <td>0.044446</td>\n",
       "      <td>0.015322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060740</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.010824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.039148</td>\n",
       "      <td>0.055069</td>\n",
       "      <td>0.050611</td>\n",
       "      <td>0.039101</td>\n",
       "      <td>0.044359</td>\n",
       "      <td>0.031924</td>\n",
       "      <td>0.028422</td>\n",
       "      <td>0.047168</td>\n",
       "      <td>0.091028</td>\n",
       "      <td>0.048559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022713</td>\n",
       "      <td>0.025653</td>\n",
       "      <td>0.031669</td>\n",
       "      <td>0.036193</td>\n",
       "      <td>0.032029</td>\n",
       "      <td>0.026704</td>\n",
       "      <td>0.060740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.005203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.039159</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>0.007815</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.037978</td>\n",
       "      <td>0.030906</td>\n",
       "      <td>0.035077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031969</td>\n",
       "      <td>0.029121</td>\n",
       "      <td>0.081960</td>\n",
       "      <td>0.038871</td>\n",
       "      <td>0.029176</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.041565</td>\n",
       "      <td>0.021278</td>\n",
       "      <td>0.020025</td>\n",
       "      <td>0.022963</td>\n",
       "      <td>0.019603</td>\n",
       "      <td>0.019767</td>\n",
       "      <td>0.012143</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>0.034523</td>\n",
       "      <td>0.024425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020811</td>\n",
       "      <td>0.038220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>0.024646</td>\n",
       "      <td>0.027652</td>\n",
       "      <td>0.010824</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.020047</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   1.000000  0.080066  0.061542  0.058908  0.052581  0.060854  0.051660   \n",
       "1   0.080066  1.000000  0.104372  0.096369  0.035761  0.039454  0.074098   \n",
       "2   0.061542  0.104372  1.000000  0.046375  0.053976  0.030418  0.065979   \n",
       "3   0.058908  0.096369  0.046375  1.000000  0.035663  0.050514  0.069387   \n",
       "4   0.052581  0.035761  0.053976  0.035663  1.000000  0.038615  0.057243   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.054693  0.059608  0.023985  0.025298  0.069555  0.025346  0.054146   \n",
       "96  0.058060  0.021587  0.121208  0.022265  0.024194  0.037258  0.051903   \n",
       "97  0.039148  0.055069  0.050611  0.039101  0.044359  0.031924  0.028422   \n",
       "98  0.039159  0.011562  0.007815  0.011478  0.013811  0.023125  0.005583   \n",
       "99  0.041565  0.021278  0.020025  0.022963  0.019603  0.019767  0.012143   \n",
       "\n",
       "          7         8         9   ...        90        91        92        93  \\\n",
       "0   0.043490  0.089278  0.068814  ...  0.069883  0.028730  0.062394  0.052185   \n",
       "1   0.094881  0.028813  0.063958  ...  0.044616  0.059069  0.077800  0.061235   \n",
       "2   0.085059  0.012954  0.037902  ...  0.013196  0.071385  0.044981  0.003269   \n",
       "3   0.082785  0.071459  0.036879  ...  0.024534  0.053544  0.036607  0.034040   \n",
       "4   0.042069  0.039807  0.038635  ...  0.023546  0.022473  0.031935  0.029203   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "95  0.022813  0.030327  0.029828  ...  0.044763  0.024386  0.055134  0.046696   \n",
       "96  0.026425  0.043188  0.052317  ...  0.016540  0.057773  0.024460  0.042650   \n",
       "97  0.047168  0.091028  0.048559  ...  0.022713  0.025653  0.031669  0.036193   \n",
       "98  0.037978  0.030906  0.035077  ...  0.031969  0.029121  0.081960  0.038871   \n",
       "99  0.015097  0.034523  0.024425  ...  0.020811  0.038220  0.000000  0.013921   \n",
       "\n",
       "          94        95        96        97        98        99  \n",
       "0   0.052840  0.054693  0.058060  0.039148  0.039159  0.041565  \n",
       "1   0.019349  0.059608  0.021587  0.055069  0.011562  0.021278  \n",
       "2   0.030303  0.023985  0.121208  0.050611  0.007815  0.020025  \n",
       "3   0.027670  0.025298  0.022265  0.039101  0.011478  0.022963  \n",
       "4   0.040399  0.069555  0.024194  0.044359  0.013811  0.019603  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "95  0.030511  1.000000  0.015322  0.026704  0.025253  0.027652  \n",
       "96  0.044446  0.015322  1.000000  0.060740  0.019970  0.010824  \n",
       "97  0.032029  0.026704  0.060740  1.000000  0.008955  0.005203  \n",
       "98  0.029176  0.025253  0.019970  0.008955  1.000000  0.020047  \n",
       "99  0.024646  0.027652  0.010824  0.005203  0.020047  1.000000  \n",
       "\n",
       "[100 rows x 100 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "similarity_df = pd.DataFrame(cosine_similarities)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1  # Ajusta el umbral según tu criterio\n",
    "\n",
    "similar_pairs = []\n",
    "for i in range(len(documents)):\n",
    "    for j in range(i+1, len(documents)):\n",
    "        if cosine_similarities[i][j] > threshold:\n",
    "            similar_pairs.append((titles[i], titles[j], cosine_similarities[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>The Witches Hammer (2006)</td>\n",
       "      <td>The Midnight Meat Train (2008)</td>\n",
       "      <td>0.196291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Prizzi's Honor (1985)</td>\n",
       "      <td>Rånarna (2003)</td>\n",
       "      <td>0.182096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Universal Soldier: The Return (1999)</td>\n",
       "      <td>The Midnight Meat Train (2008)</td>\n",
       "      <td>0.177575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Universal Soldier: The Return (1999)</td>\n",
       "      <td>Love.com (2002)</td>\n",
       "      <td>0.176448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Universal Soldier: The Return (1999)</td>\n",
       "      <td>The Witches Hammer (2006)</td>\n",
       "      <td>0.176369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Love.com (2002)</td>\n",
       "      <td>The Midnight Meat Train (2008)</td>\n",
       "      <td>0.168070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Second to Die (2002)</td>\n",
       "      <td>Ekstase (1933)</td>\n",
       "      <td>0.167074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Ricordati di me (2003)</td>\n",
       "      <td>Tigerland (2000)</td>\n",
       "      <td>0.157326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Universal Soldier: The Return (1999)</td>\n",
       "      <td>United (2003)</td>\n",
       "      <td>0.154534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>The Witches Hammer (2006)</td>\n",
       "      <td>Love.com (2002)</td>\n",
       "      <td>0.153113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title1                           title2  \\\n",
       "92              The Witches Hammer (2006)   The Midnight Meat Train (2008)    \n",
       "124                 Prizzi's Honor (1985)                   Rånarna (2003)    \n",
       "62   Universal Soldier: The Return (1999)   The Midnight Meat Train (2008)    \n",
       "61   Universal Soldier: The Return (1999)                  Love.com (2002)    \n",
       "60   Universal Soldier: The Return (1999)        The Witches Hammer (2006)    \n",
       "126                       Love.com (2002)   The Midnight Meat Train (2008)    \n",
       "63                   Second to Die (2002)                   Ekstase (1933)    \n",
       "58                 Ricordati di me (2003)                 Tigerland (2000)    \n",
       "59   Universal Soldier: The Return (1999)                    United (2003)    \n",
       "88              The Witches Hammer (2006)                  Love.com (2002)    \n",
       "\n",
       "       cosine  \n",
       "92   0.196291  \n",
       "124  0.182096  \n",
       "62   0.177575  \n",
       "61   0.176448  \n",
       "60   0.176369  \n",
       "126  0.168070  \n",
       "63   0.167074  \n",
       "58   0.157326  \n",
       "59   0.154534  \n",
       "88   0.153113  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(similar_pairs, columns=[\"title1\", \"title2\", \"cosine\"])\n",
    "new_result_df = result_df.sort_values(by='cosine', ascending=False)\n",
    "\n",
    "new_result_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
